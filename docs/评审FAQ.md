# 评审 FAQ（Judge FAQ）

目的：帮助评委在短时间内理解边界、风险与可验证点，便于现场追问与打分。

## 使用与环境
- 是否支持内网/弱网？
  - 支持。本地优先架构，调用外部模型时可配置 HTTP/HTTPS 代理；也可接入私有/本地推理服务。
- 需要哪些前置环境？
  - Node.js 18+、Rust 稳定版、@tauri-apps/cli；Windows 建议使用 PowerShell。
- 如何快速跑通？
  - npm install → 拷贝 `config.example.toml` 并填入 API Key → `npm run tauri:dev`。

## 数据与合规
- 数据是否出网？
  - 本地 SQLite 与文件系统存储；仅在调用外部模型时出网，可通过企业代理；日志可关闭或脱敏。
- 是否支持审计与回溯？
  - 支持。版本点、阶段日志与证据记录可回放与对照。

## 能力与边界
- 为什么多智能体比单 Agent 更稳？
  - 多角色互评降低偏置，配合“完整度阈值 + 最大轮次”门控，防止过早或过度收敛。
- 产生幻觉怎么办？
  - 验证阶段显示证据、置信度与不确定性；可重跑阶段、调整阈值、切换模型或增加检索。
- 是否支持离线？
  - 基础流程可离线；涉及外部推理需本地或内网模型服务。

## 性能与成本
- 一次完整流程多长、多贵？
  - 目标在 3 分钟内完成，成本约 ≤ $0.20/流程（因模型与网络而异）。
- 如何测量？
  - 固定输入脚本与模型，记录阶段用时、总用时、重试次数与 Token 量（如可得）。

## 路线与扩展
- 接入企业知识库？
  - 规划提供本地/内网连接器，统一检索与引用；导出将支持 PDF/PPT 模板化。
- 支持团队协作？
  - 路线包含协作权限、审计追踪与“可重放的评审脚本”。

---
如果评委希望我们当场验证具体能力，我们建议：
1) 让我们用评审机位现场输入您的真实问题；
2) 要求展示证据与不确定性并列呈现；
3) 随机切换模型、调整阈值与轮次；
4) 导出 Markdown/JSON 并打开查看结构化方案。
